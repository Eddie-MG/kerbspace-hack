{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imageai.Detection import ObjectDetection\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "execution_path = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = ObjectDetection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector.setModelTypeAsRetinaNet()\n",
    "detector.setModelPath( os.path.join(execution_path , \"resnet50_coco_best_v2.0.1.h5\"))\n",
    "detector.loadModel()\n",
    "detections = detector.detectObjectsFromImage(input_image=os.path.join(execution_path , r\"mother_fuckin_image.jpg\"), output_image_path=os.path.join(execution_path , \"imagenew1.jpg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'car',\n",
       "  'percentage_probability': 52.85045504570007,\n",
       "  'box_points': [156, 9, 174, 27]},\n",
       " {'name': 'person',\n",
       "  'percentage_probability': 60.029393434524536,\n",
       "  'box_points': [88, 77, 97, 105]},\n",
       " {'name': 'person',\n",
       "  'percentage_probability': 58.618372678756714,\n",
       "  'box_points': [75, 80, 86, 108]},\n",
       " {'name': 'person',\n",
       "  'percentage_probability': 51.33609175682068,\n",
       "  'box_points': [63, 84, 74, 113]},\n",
       " {'name': 'car',\n",
       "  'percentage_probability': 52.01278328895569,\n",
       "  'box_points': [140, 35, 165, 55]},\n",
       " {'name': 'car',\n",
       "  'percentage_probability': 81.60916566848755,\n",
       "  'box_points': [222, 36, 245, 56]},\n",
       " {'name': 'car',\n",
       "  'percentage_probability': 60.60898303985596,\n",
       "  'box_points': [141, 52, 171, 90]},\n",
       " {'name': 'car',\n",
       "  'percentage_probability': 64.5590603351593,\n",
       "  'box_points': [94, 116, 150, 171]},\n",
       " {'name': 'truck',\n",
       "  'percentage_probability': 69.25075054168701,\n",
       "  'box_points': [31, 136, 132, 237]},\n",
       " {'name': 'bus',\n",
       "  'percentage_probability': 59.40718650817871,\n",
       "  'box_points': [185, 80, 318, 284]}]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "objectList = {'car':[], 'truck':[]}\n",
    "objectTypes = ['car', 'truck']\n",
    "for eachObject in detections:\n",
    "    name = eachObject['name']\n",
    "    if name in objectTypes:\n",
    "        objectList[name].append([int((eachObject['box_points'][2:][0] + eachObject['box_points'][:2][0])/2), int((eachObject['box_points'][2:][1] + eachObject['box_points'][:2][1])/2)])\n",
    "#         objectList.append([eachObject['name'],[int((eachObject['box_points'][2:][0] + eachObject['box_points'][:2][0])/2), int((eachObject['box_points'][2:][1] + eachObject['box_points'][:2][1])/2)]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "quad_coords = {\n",
    "    \"lonlat\": np.array([\n",
    "        [51.538444, -0.102410], # corner of back telephone box\n",
    "        [51.538615, -0.102251], # far bus stop marking\n",
    "        [51.538229, -0.102508], # Post in front left\n",
    "        [51.538191, -0.102353] # Corner of dashed line bottom right\n",
    "    ]),\n",
    "    \"pixel\": np.array([\n",
    "        [131, 80],\n",
    "        [213, 32],\n",
    "        [25, 217],\n",
    "        [342, 281]\n",
    "    ])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PixelMapper(object):\n",
    "    \"\"\"\n",
    "    Create an object for converting pixels to geographic coordinates,\n",
    "    using four points with known locations which form a quadrilteral in both planes\n",
    "    Parameters\n",
    "    ----------\n",
    "    pixel_array : (4,2) shape numpy array\n",
    "        The (x,y) pixel coordinates corresponding to the top left, top right, bottom right, bottom left\n",
    "        pixels of the known region\n",
    "    lonlat_array : (4,2) shape numpy array\n",
    "        The (lon, lat) coordinates corresponding to the top left, top right, bottom right, bottom left\n",
    "        pixels of the known region\n",
    "    \"\"\"\n",
    "    def __init__(self, pixel_array, lonlat_array):\n",
    "        assert pixel_array.shape==(4,2), \"Need (4,2) input array\"\n",
    "        assert lonlat_array.shape==(4,2), \"Need (4,2) input array\"\n",
    "        self.M = cv2.getPerspectiveTransform(np.float32(pixel_array),np.float32(lonlat_array))\n",
    "        self.invM = cv2.getPerspectiveTransform(np.float32(lonlat_array),np.float32(pixel_array))\n",
    "        \n",
    "    def pixel_to_lonlat(self, pixel):\n",
    "        \"\"\"\n",
    "        Convert a set of pixel coordinates to lon-lat coordinates\n",
    "        Parameters\n",
    "        ----------\n",
    "        pixel : (N,2) numpy array or (x,y) tuple\n",
    "            The (x,y) pixel coordinates to be converted\n",
    "        Returns\n",
    "        -------\n",
    "        (N,2) numpy array\n",
    "            The corresponding (lon, lat) coordinates\n",
    "        \"\"\"\n",
    "        if type(pixel) != np.ndarray:\n",
    "            pixel = np.array(pixel).reshape(1,2)\n",
    "        assert pixel.shape[1]==2, \"Need (N,2) input array\" \n",
    "        pixel = np.concatenate([pixel, np.ones((pixel.shape[0],1))], axis=1)\n",
    "        lonlat = np.dot(self.M,pixel.T)\n",
    "        \n",
    "        return (lonlat[:2,:]/lonlat[2,:]).T\n",
    "    \n",
    "    def lonlat_to_pixel(self, lonlat):\n",
    "        \"\"\"\n",
    "        Convert a set of lon-lat coordinates to pixel coordinates\n",
    "        Parameters\n",
    "        ----------\n",
    "        lonlat : (N,2) numpy array or (x,y) tuple\n",
    "            The (lon,lat) coordinates to be converted\n",
    "        Returns\n",
    "        -------\n",
    "        (N,2) numpy array\n",
    "            The corresponding (x, y) pixel coordinates\n",
    "        \"\"\"\n",
    "        if type(lonlat) != np.ndarray:\n",
    "            lonlat = np.array(lonlat).reshape(1,2)\n",
    "        assert lonlat.shape[1]==2, \"Need (N,2) input array\" \n",
    "        lonlat = np.concatenate([lonlat, np.ones((lonlat.shape[0],1))], axis=1)\n",
    "        pixel = np.dot(self.invM,lonlat.T)\n",
    "        \n",
    "        return (pixel[:2,:]/pixel[2,:]).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm = PixelMapper(quad_coords[\"pixel\"], quad_coords[\"lonlat\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "uv_0 = (131, 80) # Top left give way sign in frame\n",
    "lonlat_0 = pm.pixel_to_lonlat(uv_0)\n",
    "uv_2 = (213, 32)\n",
    "lonlat_2 = pm.pixel_to_lonlat(uv_2)\n",
    "uv_3 = (100,120)\n",
    "lonlat_3 = pm.pixel_to_lonlat(uv_3)\n",
    "uv_4 = (159,195)\n",
    "lonlat_4 = pm.pixel_to_lonlat(uv_4)\n",
    "uv_5 = (300, 110)\n",
    "lonlat_5 = pm.pixel_to_lonlat(uv_5)\n",
    "\n",
    "lonlat_1 = (6.603361, 52.036639) # Center of the roundabout on googlemaps\n",
    "uv_1 = pm.lonlat_to_pixel(lonlat_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[51.53824717, -0.10241868]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lonlat_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'apple',\n",
       "  'percentage_probability': 91.35767221450806,\n",
       "  'box_points': [1166, 882, 2329, 2041]}]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'car': [[165, 18], [152, 45], [233, 46], [156, 71], [122, 143]],\n",
       " 'truck': [[81, 186]]}"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "objectList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "51.538348, -0.102444"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pixelToCoor(dic):\n",
    "    pm = PixelMapper(quad_coords[\"pixel\"], quad_coords[\"lonlat\"])\n",
    "    coordic = {}\n",
    "    for k,v in dic.items():\n",
    "        coords = []\n",
    "        for pix in v:\n",
    "            coords.append(pm.pixel_to_lonlat(pix).tolist()[0])\n",
    "        coordic[k] = coords\n",
    "    return coordic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "convcoords = pixelToCoor(objectList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'car': [[51.53878106367503, -0.10229043089634901],\n",
       "  [51.5385863351056, -0.10235664306456346],\n",
       "  [51.53853099533867, -0.1022559291367989],\n",
       "  [51.53846687287516, -0.10237498442851745],\n",
       "  [51.538308412855656, -0.10243596755262753]],\n",
       " 'truck': [[51.53825767058105, -0.1024707151003526]]}"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convcoords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Old\n",
    "### 51.538727, -0.102328\n",
    "### 51.53834125, -0.10228305\n",
    "\n",
    "## New Bad\n",
    "\n",
    "### 51.538203, -0.102467\n",
    "### 51.538729, -0.102364\n",
    "\n",
    "## New New\n",
    "### 51.538200, -0.102517\n",
    "### 51.538732, -0.102331"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objselect(dic, crdx, crdy):\n",
    "    for k,v in dic.items():\n",
    "        for i, cd in enumerate(v):\n",
    "            if cd[0] > max(crdx) or cd[0] < min(crdx) or cd[1] > max(crdy) or cd[1] < min(crdy):\n",
    "                v.pop(i)\n",
    "    return dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'car': [[51.5385863351056, -0.10235664306456346],\n",
       "  [51.53846687287516, -0.10237498442851745],\n",
       "  [51.538308412855656, -0.10243596755262753]],\n",
       " 'truck': [[51.53825767058105, -0.1024707151003526]]}"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "objselect(convcoords, [51.538200, 51.538732], [-0.102517,  -0.102331])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[51.53825767058105, -0.1024707151003526]]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convcoords['truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[51.53878106367503, -0.10229043089634901],\n",
       " [51.5385863351056, -0.10235664306456346],\n",
       " [51.53853099533867, -0.1022559291367989],\n",
       " [51.53846687287516, -0.10237498442851745],\n",
       " [51.538308412855656, -0.10243596755262753]]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convcoords['car']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
