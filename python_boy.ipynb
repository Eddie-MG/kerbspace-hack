{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from imageai.Detection import ObjectDetection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "execution_path = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = ObjectDetection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\kaija\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "tracking <tf.Variable 'Variable:0' shape=(9, 4) dtype=float32> anchors\n",
      "tracking <tf.Variable 'Variable_1:0' shape=(9, 4) dtype=float32> anchors\n",
      "tracking <tf.Variable 'Variable_2:0' shape=(9, 4) dtype=float32> anchors\n",
      "tracking <tf.Variable 'Variable_3:0' shape=(9, 4) dtype=float32> anchors\n",
      "tracking <tf.Variable 'Variable_4:0' shape=(9, 4) dtype=float32> anchors\n"
     ]
    }
   ],
   "source": [
    "detector.setModelTypeAsRetinaNet()\n",
    "detector.setModelPath( os.path.join(execution_path , \"resnet50_coco_best_v2.0.1.h5\"))\n",
    "detector.loadModel()\n",
    "detections = detector.detectObjectsFromImage(input_image=os.path.join(execution_path , \"mother_fuckin_image.jpg\"), output_image_path=os.path.join(execution_path , \"imagenew1.jpg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'car', 'percentage_probability': 52.85045504570007, 'box_points': [156, 9, 174, 27]}\n",
      "[165, 18]\n",
      "{'name': 'person', 'percentage_probability': 60.029393434524536, 'box_points': [88, 77, 97, 105]}\n",
      "[92, 91]\n",
      "{'name': 'person', 'percentage_probability': 58.618372678756714, 'box_points': [75, 80, 86, 108]}\n",
      "[80, 94]\n",
      "{'name': 'person', 'percentage_probability': 51.33609175682068, 'box_points': [63, 84, 74, 113]}\n",
      "[68, 98]\n",
      "{'name': 'car', 'percentage_probability': 52.01278328895569, 'box_points': [140, 35, 165, 55]}\n",
      "[152, 45]\n",
      "{'name': 'car', 'percentage_probability': 81.60916566848755, 'box_points': [222, 36, 245, 56]}\n",
      "[233, 46]\n",
      "{'name': 'car', 'percentage_probability': 60.60898303985596, 'box_points': [141, 52, 171, 90]}\n",
      "[156, 71]\n",
      "{'name': 'car', 'percentage_probability': 64.5590603351593, 'box_points': [94, 116, 150, 171]}\n",
      "[122, 143]\n",
      "{'name': 'truck', 'percentage_probability': 69.25075054168701, 'box_points': [31, 136, 132, 237]}\n",
      "[81, 186]\n",
      "{'name': 'bus', 'percentage_probability': 59.40718650817871, 'box_points': [185, 80, 318, 284]}\n",
      "[251, 182]\n"
     ]
    }
   ],
   "source": [
    "for eachObject in detections:\n",
    "    print(eachObject)\n",
    "    print([int((eachObject['box_points'][2:][0] + eachObject['box_points'][:2][0])/2), int((eachObject['box_points'][2:][1] + eachObject['box_points'][:2][1])/2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "quad_coords = {\n",
    "    \"lonlat\": np.array([\n",
    "        [51.538444, -0.102410], # corner of back telephone box\n",
    "        [51.538615, -0.102251], # far bus stop marking\n",
    "        [51.538229, -0.102508], # Post in front left\n",
    "        [51.538191, -0.102353] # Corner of dashed line bottom right\n",
    "    ]),\n",
    "    \"pixel\": np.array([\n",
    "        [131, 80],\n",
    "        [213, 32],\n",
    "        [25, 217],\n",
    "        [342, 281]\n",
    "    ])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "\n",
    "class PixelMapper(object):\n",
    "    \"\"\"\n",
    "    Create an object for converting pixels to geographic coordinates,\n",
    "    using four points with known locations which form a quadrilteral in both planes\n",
    "    Parameters\n",
    "    ----------\n",
    "    pixel_array : (4,2) shape numpy array\n",
    "        The (x,y) pixel coordinates corresponding to the top left, top right, bottom right, bottom left\n",
    "        pixels of the known region\n",
    "    lonlat_array : (4,2) shape numpy array\n",
    "        The (lon, lat) coordinates corresponding to the top left, top right, bottom right, bottom left\n",
    "        pixels of the known region\n",
    "    \"\"\"\n",
    "    def __init__(self, pixel_array, lonlat_array):\n",
    "        assert pixel_array.shape==(4,2), \"Need (4,2) input array\"\n",
    "        assert lonlat_array.shape==(4,2), \"Need (4,2) input array\"\n",
    "        self.M = cv2.getPerspectiveTransform(np.float32(pixel_array),np.float32(lonlat_array))\n",
    "        self.invM = cv2.getPerspectiveTransform(np.float32(lonlat_array),np.float32(pixel_array))\n",
    "        \n",
    "    def pixel_to_lonlat(self, pixel):\n",
    "        \"\"\"\n",
    "        Convert a set of pixel coordinates to lon-lat coordinates\n",
    "        Parameters\n",
    "        ----------\n",
    "        pixel : (N,2) numpy array or (x,y) tuple\n",
    "            The (x,y) pixel coordinates to be converted\n",
    "        Returns\n",
    "        -------\n",
    "        (N,2) numpy array\n",
    "            The corresponding (lon, lat) coordinates\n",
    "        \"\"\"\n",
    "        if type(pixel) != np.ndarray:\n",
    "            pixel = np.array(pixel).reshape(1,2)\n",
    "        assert pixel.shape[1]==2, \"Need (N,2) input array\" \n",
    "        pixel = np.concatenate([pixel, np.ones((pixel.shape[0],1))], axis=1)\n",
    "        lonlat = np.dot(self.M,pixel.T)\n",
    "        \n",
    "        return (lonlat[:2,:]/lonlat[2,:]).T\n",
    "    \n",
    "    def lonlat_to_pixel(self, lonlat):\n",
    "        \"\"\"\n",
    "        Convert a set of lon-lat coordinates to pixel coordinates\n",
    "        Parameters\n",
    "        ----------\n",
    "        lonlat : (N,2) numpy array or (x,y) tuple\n",
    "            The (lon,lat) coordinates to be converted\n",
    "        Returns\n",
    "        -------\n",
    "        (N,2) numpy array\n",
    "            The corresponding (x, y) pixel coordinates\n",
    "        \"\"\"\n",
    "        if type(lonlat) != np.ndarray:\n",
    "            lonlat = np.array(lonlat).reshape(1,2)\n",
    "        assert lonlat.shape[1]==2, \"Need (N,2) input array\" \n",
    "        lonlat = np.concatenate([lonlat, np.ones((lonlat.shape[0],1))], axis=1)\n",
    "        pixel = np.dot(self.invM,lonlat.T)\n",
    "        \n",
    "        return (pixel[:2,:]/pixel[2,:]).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm = PixelMapper(quad_coords[\"pixel\"], quad_coords[\"lonlat\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "uv_0 = (131, 80) # Top left give way sign in frame\n",
    "lonlat_0 = pm.pixel_to_lonlat(uv_0)\n",
    "uv_2 = (213, 32)\n",
    "lonlat_2 = pm.pixel_to_lonlat(uv_2)\n",
    "uv_3 = (100,120)\n",
    "lonlat_3 = pm.pixel_to_lonlat(uv_3)\n",
    "uv_4 = (159,195)\n",
    "lonlat_4 = pm.pixel_to_lonlat(uv_4)\n",
    "uv_5 = (300, 110)\n",
    "lonlat_5 = pm.pixel_to_lonlat(uv_5)\n",
    "\n",
    "lonlat_1 = (6.603361, 52.036639) # Center of the roundabout on googlemaps\n",
    "uv_1 = pm.lonlat_to_pixel(lonlat_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[51.53824717, -0.10241868]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lonlat_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "51.538348, -0.102444"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
